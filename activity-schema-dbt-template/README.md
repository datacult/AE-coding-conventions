# Activity Schema dbt Template

A production-ready dbt template for implementing activity schema data modeling with identity resolution and temporal join analysis (WIP).

## üéØ What is Activity Schema?

Activity schema is an event-centric data modeling approach that:
- Treats every business event as a first-class entity
- Enables temporal relationship analysis between activities
- Handles identity resolution across anonymous and known user states
- Provides flexible, behavioral-driven insights

Refer to the documentation [here](https://www.notion.so/Activity-Schema-Docs-224fa8808c1b80e9982be516399656ce) for more deepdive into the Activity Schema paradigm and its philosophical approach

This template provides a complete framework with pre-built macros, identity resolution logic, and temporal join patterns (WIP).

## üìã Prerequisites

- dbt Core or dbt Cloud
- Snowflake, BigQuery, or Redshift data warehouse
- Basic understanding of dbt project structure
- Raw event data from your application/website

## üöÄ Quick Start

### 1. Clone the Repository

```bash
git clone https://github.com/datacult/AE-coding-conventions.git
cd activity-schema-dbt-template
```

### 3. Configure Your Data Warehouse

Update `profiles.yml` with your warehouse credentials as required. 

## üìÅ Project Structure

```
activity_schema_dbt_template/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ staging/                          # üîß CUSTOMIZE: Your data sources
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ _sources.yml                  # Define raw data sources
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stg_web_events.sql           # Clean web analytics data
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stg_user_data.sql            # Clean user/CRM data
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ stg_other_events.sql         # Other activity sources
‚îÇ   ‚îú‚îÄ‚îÄ identity/                         # üìã COPY AS-IS: Identity resolution
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ identity__person_stream.sql   # üìù Template + customize WHERE clause
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ identity_change_detector.sql  # üìã Copy exactly
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ identity_time_windows.sql     # üìã Copy exactly
‚îÇ   ‚îú‚îÄ‚îÄ intermediate/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ activity_streams/             # üìù TEMPLATES: Customize per activity
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ person_stream_signed_up.sql
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ person_stream_made_purchase.sql
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ person_stream_started_session.sql
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ _activity_streams.yml     # Documentation/tests
‚îÇ   ‚îî‚îÄ‚îÄ marts/
‚îÇ       ‚îú‚îÄ‚îÄ core/                         # üîß CUSTOMIZE: Business needs
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ dim_customers.sql
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ fct_daily_activities.sql
‚îÇ       ‚îî‚îÄ‚îÄ analysis/                     # üìù TEMPLATES: Business questions
‚îÇ           ‚îú‚îÄ‚îÄ conversion_analysis.sql
‚îÇ           ‚îú‚îÄ‚îÄ attribution_analysis.sql
‚îÇ           ‚îî‚îÄ‚îÄ churn_analysis.sql
‚îú‚îÄ‚îÄ macros/
‚îÇ   ‚îú‚îÄ‚îÄ activity_schema/                  # üìã COPY AS-IS: Core framework
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ resolve_identity.sql
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ complete_temporal_join.sql
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ enhanced_multi_temporal_analysis.sql
‚îÇ   ‚îî‚îÄ‚îÄ business_logic/                   # üîß CUSTOMIZE: Client-specific
‚îÇ       ‚îî‚îÄ‚îÄ custom_metrics.sql
‚îú‚îÄ‚îÄ tests/                                # Data quality tests
‚îÇ   ‚îú‚îÄ‚îÄ activity_schema/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_identity_coverage.sql
‚îÇ   ‚îî‚îÄ‚îÄ reconciliation/
‚îÇ       ‚îî‚îÄ‚îÄ test_revenue_reconciliation.sql
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ IMPLEMENTATION_GUIDE.md           # Step-by-step setup
‚îÇ   ‚îú‚îÄ‚îÄ TEMPORAL_JOINS_REFERENCE.md       # All 12 join types
‚îÇ   ‚îî‚îÄ‚îÄ DECISION_MATRIX.md                # Business question ‚Üí Join type
‚îú‚îÄ‚îÄ dbt_project.yml
‚îú‚îÄ‚îÄ packages.yml
‚îî‚îÄ‚îÄ README.md
```

### üìÇ File Legend

- üìã **Copy As-Is**: Use these files exactly as provided (core framework)
- üìù **Template + Customize**: Follow the template pattern, customize for your data
- üîß **Fully Customize**: Build these based on the client's business needs and other data exploration done and agreed activities defined as aligned with the Client leveraging the design methodological [here](https://www.notion.so/The-Activity-Schema-Data-Model-Design-228fa8808c1b80f78becf6fdd750bf8c)

## üéì Implementation Guide

Refer to the documentation [here](https://www.notion.so/The-Activity-Schema-Data-Model-Implementation-269fa8808c1b80e5a8f8c15a59910846) for more deepdive

### Step 1: Create all Staging Models and required Intermediate models

### Step 2: Set Up Identity Resolution

Identity resolution connects anonymous and known user activities.

**1. Define where users reveal their identity:**

Edit `models/identity/identity__person_stream.sql`:

```sql
-- Add your identity-revealing activities
select * 
from {{ ref('stg_payment_strip') }}
where customer is not null 
  anonymous_customer_id is not null 

union all
select * from {{ ref('stg_sign_up') }}
where customer is not null 
  anonymous_customer_id is not null 

union all
.....
-- Add other activities where users reveal identity
```

**2. The framework handles the rest automatically** via:
- `identity_change_detector.sql` (tracks identity changes)
- `identity_time_windows.sql` (creates identity resolution windows)

### Step 2: Create Activity Streams

Activity streams are standardized representations of business events.

**Template Pattern:**

**Activities that Require Identity Resolution**
see -> models/intermediate/person_stream/person_stream_viewed_pages.sql

```sql
-- models/intermediate/activity_streams/person_stream_[activity_name].sql
{{ config(materialized='table') }}

{% call resolve_identity() %}
select 
    {{ dbt_utils.generate_surrogate_key(['user_id', 'timestamp']) }} as activity_id,
    user_id as anonymous_customer_id,
    customer,  -- Will be resolved by macro where necessary
    '[activity_name]' as activity,
    timestamp as ts,
    revenue_amount as revenue_impact,
    page_url as link,
    
    -- Store event attributes as JSON
    object_construct(
        'product_id', product_id,
        'category', category,
        'utm_source', utm_source
    ) as feature_json
    
from {{ ref('stg_web_events') }}
where event_type = '[your_event_type]'
{% endcall %}
```

**Create one for each key activity:**
- `person_stream_signed_up.sql`
- `person_stream_made_purchase.sql`
- `person_stream_started_session.sql`
- `person_stream_viewed_product.sql`
- etc.


**Activities that do not Require Identity Resolution**
see -> models/intermediate/person_stream/person_stream_sign_up.sql


```sql 

-- models/intermediate/activity_streams/person_stream_[activity_name].sql
{{ config(materialized='table') }}

select 
    {{ dbt_utils.generate_surrogate_key(['user_id', 'timestamp']) }} as activity_id,
    user_id as anonymous_customer_id,
    customer,  
    activity,
    timestamp as ts,
    revenue_amount as revenue_impact,
    page_url as link,
    
    -- Store event attributes as JSON
    object_construct(
        'product_id', product_id,
        'category', category,
        'utm_source', utm_source
    ) as feature_json,
    
    row_number() over (
        partition by user_id 
        order by timestamp
    ) as activity_occurrence,
    
    lead(timestamp) over (
        partition by user_id 
        order by timestamp
    ) as activity_repeated_at
    
from {{ ref('stg_web_events') }} ---- REPLACE THE STAGING/INTERMEDIATE MODELS
where event_type = '[your_event_type]'
```

### Step 3: Build Analysis Models

Use temporal joins to answer business questions.

**Example: Conversion Analysis**

```sql
-- models/marts/analysis/conversion_analysis.sql

{{ temporal_join(
    cohort_activity='signed_up_v2',
    target_activity='used_model_v2', 
    join_type='first_after',
    cohort_filter='first'
) }}

```

```sql
{{ multi_temporal_analysis(
    primary_cohort_activity='started_session_v2', 
    join_configs=[
        {
            'name': 'signed_up',
            'target_activity': 'signed_up_v2',
            'join_type': 'first_after'
        },
        {
            'name': 'used_model',
            'target_activity': 'used_model_v2',
            'join_type': 'first_after'
        }
    ],
    cohort_filter='first'
) }}

```


### Step 4: Build Dimensional Models (Optional)

Create familiar dimensional models for BI tools where necessary ontop of the activity streams:

```sql
-- models/marts/core/dim_customers.sql
-- Build customer dimension from activity streams
```

## üìä The 12 Temporal Join Types

Refer to the documentation on [Temporal Joins Basics](https://www.notion.so/Temporal-Joins-Basics-224fa8808c1b80da9b4ff347c728ad74) and [dbt Implementation](https://www.notion.so/dbt-Activity-Schema-Temporal-Joins-Framework-27dfa8808c1b807da7dfcba5fd986cec) for more deepdive 

| Join Type | Use Case | Example |
|-----------|----------|---------|
| `first_ever` | Very first occurrence | First product viewed |
| `last_ever` | Very last occurrence | Last login date |
| `aggregate_all_ever` | Lifetime totals | Total lifetime revenue |
| `first_before` | First action before event | First marketing touch before purchase |
| `last_before` | Last action before event | Last page before checkout |
| `aggregate_before` | All actions before event | Total sessions before signup |
| `first_after` | First action after event | First feature used after onboarding |
| `last_after` | Last action after event | Last activity before churning |
| `aggregate_after` | All actions after event | Total purchases after signup |
| `first_in_between` | First in session/period | First page in session |
| `last_in_between` | Last in session/period | Exit page in session |
| `aggregate_in_between` | All in session/period | Total pages per session |


## üß™ Validation/Testing

Refer to this [documentation](https://www.notion.so/Guide-Activity-Schema-Validation-203fa8808c1b808381f0ce2e4a83f660#203fa8808c1b808381f0ce2e4a83f660) on the validation checklist


### Step 5: Job Orchestration and Scheduling (WIP)

üó∫Ô∏è Roadmap
- [] Learning Series on specific aspect of Activity Schema Modeling
- [] Develop an internal project on activity schema implementation similar to [dbt jaffle shop](google.com/search?q=dbt+jaffle+shop&oq=dbt+jaffle+shop&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQABiABDIHCAIQABiABDIHCAMQABiABDIHCAQQABiABDIHCAUQABiABDIICAYQABgWGB4yCAgHEAAYFhgeMggICBAAGBYYHjIICAkQABgWGB7SAQgyNTMxajBqNKgCALACAQ&sourceid=chrome&ie=UTF-8) that can be used as testing and learning resource
- [] Pre-built industry templates (e-commerce, SaaS, etc.) as we work with different clients leveraging activity schema
- [] Enhanced current temporal join and multi-analysis temploral join patterns
- [] Machine learning feature generation patterns

üôè Acknowledgments

* Activity schema concept from Narrator
* Inspired by dbt best practices 

üìû Feedback

Feel free to make update and communicate any inherent issues observed as you work with the different templates


**Built with ‚ù§Ô∏è for the DC analytics engineering team - Shout to David/Brittany helping out on this knowledge base**